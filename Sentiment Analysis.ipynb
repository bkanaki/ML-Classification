{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Product reviews sentiment analysis using sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the pandas libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "products = pd.read_csv('amazon_baby.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                           Planetwise Flannel Wipes   \n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \n",
       "0  These flannel wipes are OK, but in my opinion ...       3  \n",
       "1  it came early and was not disappointed. i love...       5  \n",
       "2  Very soft and comfortable and warmer than it l...       5  \n",
       "3  This is a product well worth the purchase.  I ...       5  \n",
       "4  All of my kids have cried non-stop when I trie...       5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view data\n",
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = products.fillna({'review':''})  # fill in N/A's in the review column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function to remove punctuation marks from the reviews. - Data Cleaning step\n",
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    if type(text) is str: # needed because data frame will return the index of rows\n",
    "        return text.translate(None, string.punctuation)\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# apply this function to reviews and add new column with the clean data\n",
    "products['review_clean'] = products['review'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract sentiments that are not equal to 3 as thy represent neutral sentiment\n",
    "products = products[products['rating']!=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Assign sentiments -> +1 or -1 based on the rating\n",
    "products['sentiment'] = products['rating'].apply(lambda rating : +1 if rating > 3 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split data into train and test with 80/20 ratio\n",
    "from sklearn.cross_validation import train_test_split\n",
    "train_data, test_data = train_test_split(products, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate bag-of-words features by counting occurances of each wors in a review\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "     # Use this token pattern to keep single-letter words\n",
    "# First, learn vocabulary from the training data and assign columns to words\n",
    "# Then convert the training data into a sparse matrix\n",
    "train_matrix = vectorizer.fit_transform(train_data['review_clean'])\n",
    "# Second, convert the test data into a sparse matrix, using the same word-column mapping\n",
    "test_matrix = vectorizer.transform(test_data['review_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(train_matrix, train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85151"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quiz question - How many weights are >= 0? - check the other one\n",
    "(model.coef_ >= 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    index                                               name  \\\n",
      "0   39824  Graco Baby SnugGlider Infant Car Seat Swing Frame   \n",
      "1  131632  The First Years MiSwivel Feeding Seat, Dot to Dot   \n",
      "2   92029  BooginHead PaciGrip Pacifier Holder Green Dot ...   \n",
      "\n",
      "                                              review  rating  \\\n",
      "0  My lil one is currently 12 days old and spends...       5   \n",
      "1  I love this high chair and so does my 5 month ...       4   \n",
      "2  Item is accurately described and works wonderf...       5   \n",
      "\n",
      "                                        review_clean  sentiment  \n",
      "0  My lil one is currently 12 days old and spends...          1  \n",
      "1  I love this high chair and so does my 5 month ...          1  \n",
      "2  Item is accurately described and works wonderf...          1  \n"
     ]
    }
   ],
   "source": [
    "sample_test_data = test_data[13:16]\n",
    "sample_test_data = sample_test_data.reset_index()\n",
    "print sample_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"My lil one is currently 12 days old and spends most of her day in the seat attached to this swing. I have yet to change the batteries and I just used the cheapies from the dollar tree! I am greatly surprised! I love the fact that there is nothing above the swing to bump the baby's head on, and its easier to get the baby out.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data.at[0, 'review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I love this high chair and so does my 5 month old son, but since the straps are white in color they get dirty easily. I have been using this chair for 2 months now and even though I diligently cleaned the straps after every use they are now a yellowish color. I have tried everything to make them that brand new white color again, but to no avail. But the chair still works great and I still love it, even it's yellow straps.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data.at[1, 'review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.32793116  6.81335996  2.64182689]\n",
      "[1, 1, 1]\n",
      "[1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Predict the sentiment for sample test data\n",
    "sample_test_matrix = vectorizer.transform(sample_test_data['review_clean'])\n",
    "scores = model.decision_function(sample_test_matrix)\n",
    "print scores\n",
    "my_pred_senti = map(lambda score: 1 if score > 0 else -1, scores)\n",
    "print my_pred_senti\n",
    "print model.predict(test_matrix[13:16,:])      # compare with the predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print model.predict(test_matrix[13:16,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<33351x121659 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 1808342 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96537468246681579, 0.99890221235170973, 0.93350545511487726]\n",
      "[ 0.96537468  0.99890221  0.93350546]\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities\n",
    "from numpy import exp\n",
    "my_pred_senti_prob = map(lambda score: float(1)/(1 + exp(-score)), scores)\n",
    "print my_pred_senti_prob\n",
    "print model.predict_proba(test_matrix[13:16,:]) [:,1]     # compare with the predict function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Need to load the pre-split train and test data to answer questions for quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_idx = pd.read_json('module-2-assignment-train-idx.json', typ='series')\n",
    "test_data_idx = pd.read_json('module-2-assignment-test-idx.json', typ='series')\n",
    "# ^ in the lines above, very important to read in as Series.\n",
    "train_data = products.iloc[train_data_idx]\n",
    "test_data = products.iloc[test_data_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate bag-of-words features by counting occurances of each wors in a review\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "     # Use this token pattern to keep single-letter words\n",
    "# First, learn vocabulary from the training data and assign columns to words\n",
    "# Then convert the training data into a sparse matrix\n",
    "train_matrix = vectorizer.fit_transform(train_data['review_clean'])\n",
    "# Second, convert the test data into a sparse matrix, using the same word-column mapping\n",
    "test_matrix = vectorizer.transform(test_data['review_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "sentiment_model = LogisticRegression()\n",
    "sentiment_model.fit(train_matrix, train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85948"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quiz question - How many weights are >= 0? - this one is correct\n",
    "(sentiment_model.coef_ >= 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index                                               name  \\\n",
      "0     59                          Our Baby Girl Memory Book   \n",
      "1     71  Wall Decor Removable Decal Sticker - Colorful ...   \n",
      "2     91  New Style Trailing Cherry Blossom Tree Decal R...   \n",
      "\n",
      "                                              review  rating  \\\n",
      "0  Absolutely love it and all of the Scripture in...       5   \n",
      "1  Would not purchase again or recommend. The dec...       2   \n",
      "2  Was so excited to get this product for my baby...       1   \n",
      "\n",
      "                                        review_clean  sentiment  \n",
      "0  Absolutely love it and all of the Scripture in...          1  \n",
      "1  Would not purchase again or recommend The deca...         -1  \n",
      "2  Was so excited to get this product for my baby...         -1  \n"
     ]
    }
   ],
   "source": [
    "sample_test_data = test_data[10:13]\n",
    "sample_test_data = sample_test_data.reset_index()\n",
    "print sample_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Absolutely love it and all of the Scripture in it.  I purchased the Baby Boy version for my grandson when he was born and my daughter-in-law was thrilled to receive the same book again.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data.at[0, 'review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Would not purchase again or recommend. The decals were thick almost plastic like and were coming off the wall as I was applying them! The would NOT stick! Literally stayed stuck for about 5 minutes then started peeling off.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data.at[1, 'review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.5961479   -3.16126785 -10.43314035]\n",
      "[1, -1, -1]\n",
      "[ 1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "# Predict the sentiment for sample test data\n",
    "sample_test_matrix = vectorizer.transform(sample_test_data['review_clean'])\n",
    "scores = sentiment_model.decision_function(sample_test_matrix)\n",
    "print scores\n",
    "my_pred_senti = map(lambda score: 1 if score > 0 else -1, scores)\n",
    "print my_pred_senti\n",
    "print sentiment_model.predict(test_matrix[10:13,:])      # compare with the predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9963015932441307, 0.040649582004875257, 2.9439601739096726e-05]\n",
      "[ 0.00369841  0.95935042  0.99997056]\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities\n",
    "from numpy import exp\n",
    "my_pred_senti_prob = map(lambda score: float(1)/(1 + exp(-score)), scores)\n",
    "print my_pred_senti_prob\n",
    "print sentiment_model.predict_proba(test_matrix[10:13,:]) [:,0]     # compare with the predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Quiz question:\n",
    "# Which of the following products are represented in the 20 most negative reviews?\n",
    "predicted_prob = sentiment_model.predict_proba(test_matrix)\n",
    "test_data['predicted_probability'] = pd.Series(predicted_prob[:,1], index=test_data.index)\n",
    "test_data = test_data.sort_values(by='predicted_probability', ascending=True)\n",
    "test_data[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Quiz question:\n",
    "# Which of the following products are represented in the 20 most positive reviews?\n",
    "test_data = test_data.sort_values(by='predicted_probability', ascending=False)\n",
    "test_data[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(data_frame):\n",
    "    correct_count = (data_frame['predicted_sentiment'] == data_frame['sentiment']).sum()\n",
    "    accuracy = float(correct_count)/len(data_frame)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_class = sentiment_model.predict(test_matrix)\n",
    "test_data['predicted_sentiment'] = pd.Series(predicted_class, index=test_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Quiz question\n",
    "# What is the accuracy of the sentiment_model on the test_data?\n",
    "print calculate_accuracy(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List of significant words to train a simplere model\n",
    "significant_words = ['love', 'great', 'easy', 'old', 'little', 'perfect', 'loves', \n",
    "      'well', 'able', 'car', 'broke', 'less', 'even', 'waste', 'disappointed', \n",
    "      'work', 'product', 'money', 'would', 'return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer_word_subset = CountVectorizer(vocabulary=significant_words) # limit to 20 words\n",
    "train_matrix_word_subset = vectorizer_word_subset.fit_transform(train_data['review_clean'])\n",
    "test_matrix_word_subset = vectorizer_word_subset.transform(test_data['review_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train the logistic regression model based on the significant words.\n",
    "simple_model = LogisticRegression()\n",
    "simple_model.fit(train_matrix_word_subset, train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Quiz Question: \n",
    "# How many of the 20 coefficients (corresponding to the 20 significant_words) \n",
    "# are positive for the simple_model?\n",
    "simple_model_coef_table = pd.DataFrame({'word':significant_words,\n",
    "                                         'coefficient':simple_model.coef_.flatten()})\n",
    "simple_model_coef_table = simple_model_coef_table.sort_values(by='coefficient', \n",
    "                                                              ascending=False)\n",
    "(simple_model_coef_table['coefficient'] > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Quiz question:\n",
    "# Which model (sentiment_model or simple_model) has higher accuracy on the TRAINING set?\n",
    "train_data['predicted_sentiment'] = pd.Series(sentiment_model.predict(train_matrix), \n",
    "                                           index=train_data.index)\n",
    "print calculate_accuracy(train_data)\n",
    "train_data['predicted_sentiment'] = pd.Series(simple_model.predict(train_matrix_word_subset), \n",
    "                                           index=train_data.index)\n",
    "print calculate_accuracy(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Quiz question:\n",
    "# Which model (sentiment_model or simple_model) has higher accuracy on the TEST set?\n",
    "test_data['predicted_sentiment'] = pd.Series(sentiment_model.predict(test_matrix), \n",
    "                                           index=test_data.index)\n",
    "print calculate_accuracy(test_data)\n",
    "test_data['predicted_sentiment'] = pd.Series(simple_model.predict(test_matrix_word_subset), \n",
    "                                           index=test_data.index)\n",
    "print calculate_accuracy(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Quiz question:\n",
    "# Enter the accuracy of the majority class classifier model on the test_data.\n",
    "num_positive  = (test_data['sentiment'] == +1).sum()\n",
    "num_negative = (test_data['sentiment'] == -1).sum()\n",
    "print num_positive\n",
    "print num_negative\n",
    "print max(num_positive, num_negative)/float(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data.at[94560, 'name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [gl-env]",
   "language": "python",
   "name": "Python [gl-env]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
